# ğŸ’³ AnÃ¡lise de Risco de CrÃ©dito - MinerAI

Este repositÃ³rio contÃ©m o projeto final da disciplina de **Data Mining**, focado na criaÃ§Ã£o de um modelo de concessÃ£o de cartÃµes de crÃ©dito para a empresa fictÃ­cia **MinerAI**.

## ğŸ¯ Objetivo
Desenvolver um algoritmo de Machine Learning capaz de classificar solicitantes de cartÃ£o de crÃ©dito em **Bons Pagadores (0)** e **Maus Pagadores (1)**, visando mitigar prejuÃ­zos financeiros decorrentes da inadimplÃªncia.

## ğŸ‘¥ Integrantes do Grupo
* **Ana Paula Velozo:** IntroduÃ§Ã£o, contexto e objetivos.
* **Gabriel Dutra:** Coleta, carregamento e descriÃ§Ã£o dos dados.
* **Iago Correa de Lima:** AnÃ¡lise univariada e bivariada (variÃ¡veis categÃ³ricas).
* **Leonardo Renner:** VisualizaÃ§Ãµes avanÃ§adas e anÃ¡lise de renda/patrimÃ´nio.
* **Persio de Souza Lima:** DetecÃ§Ã£o de outliers e modelagem (Machine Learning).

## ğŸ“Š Sobre os Dados
O dataset utilizado contÃ©m **50.000 registros** e **54 variÃ¡veis**, abrangendo:
* Dados cadastrais (Idade, Sexo, Estado Civil).
* Dados financeiros (Renda, PatrimÃ´nio).
* Dados profissionais e de moradia.
* **Target:** `ALVO MAU=1 ROTULO` (BinÃ¡rio).

> **Nota:** O dataset apresenta desbalanceamento de classes (~74% bons pagadores vs ~26% maus pagadores), o que exigiu tÃ©cnicas especÃ­ficas de tratamento.

## ğŸ› ï¸ Tecnologias Utilizadas
* **Linguagem:** Python 3
* **Bibliotecas Principais:**
    * `pandas` & `numpy`: ManipulaÃ§Ã£o de dados.
    * `matplotlib` & `seaborn` & `plotly`: VisualizaÃ§Ã£o de dados.
    * `scikit-learn`: PrÃ©-processamento e modelos (Logistic Regression, Random Forest, KNN, Naive Bayes).
    * `xgboost`: Algoritmo de Gradient Boosting.

## ğŸš€ Metodologia e Modelagem
O projeto seguiu as seguintes etapas:
1.  **EDA (AnÃ¡lise ExploratÃ³ria):** IdentificaÃ§Ã£o de padrÃµes, correlaÃ§Ãµes e outliers (rendas extremas).
2.  **PrÃ©-processamento:**
    * Limpeza de dados (tratamento de nulos em profissÃ£o e residÃªncia).
    * ConversÃ£o de variÃ¡veis categÃ³ricas.
    * DivisÃ£o em Treino/Teste (80/20).
3.  **Machine Learning:**
    Foram treinados e comparados 5 modelos diferentes.
    * *Logistic Regression*
    * *K-Nearest Neighbors (KNN)*
    * *Random Forest*
    * *Naive Bayes*
    * *XGBoost*

## ğŸ“ˆ Resultados
O modelo **XGBoost** (ou o que vocÃªs definiram como melhor no final) apresentou o melhor equilÃ­brio entre PrecisÃ£o e Recall (F1-Score), sendo o escolhido para a soluÃ§Ã£o final.

| Modelo | AcurÃ¡cia | F1-Score |
| :--- | :---: | :---: |
| XGBoost | 61% | 0.42 |
| Random Forest | 74% | 0.06 |
| Logistic Regression | 56% | 0.41 |
*(Valores aproximados obtidos durante a execuÃ§Ã£o)*

## ğŸ“‚ Estrutura do Projeto
```bash
â”œâ”€â”€ data/                # Arquivos de dados (credit.csv)
â”œâ”€â”€ notebooks/           # Jupyter Notebooks com a anÃ¡lise completa
â”œâ”€â”€ images/              # GrÃ¡ficos e imagens gerados
â”œâ”€â”€ requirements.txt     # DependÃªncias do projeto
â””â”€â”€ README.md            # DocumentaÃ§Ã£o do projeto
